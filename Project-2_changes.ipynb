{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonalvrshny/IR23-MRRS/blob/sonal-search-queries/Project-2_changes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdEkLO2CuDbW"
      },
      "outputs": [],
      "source": [
        "pip install nltk spacy tensorflow torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oiarHuyuPL9",
        "outputId": "ba31806a-674e-4c02-8bc5-e818bf546dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgkYHtfMLoaZ"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um28Z3WLkfXv"
      },
      "outputs": [],
      "source": [
        "# For english\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# For spanish\n",
        "!python -m spacy download es_core_news_sm\n",
        "\n",
        "# For hindi\n",
        "!python -m spacy download xx_ent_wiki_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSp9eQUzK_HO"
      },
      "outputs": [],
      "source": [
        "pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fw0qdd_zLnam"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "import json\n",
        "from langdetect import detect\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import langid\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from inltk.inltk import setup, tokenize\n"
      ],
      "metadata": {
        "id": "O8s47eTQ9eSP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oWW-j8oJMHFS"
      },
      "outputs": [],
      "source": [
        "# Loading and setting up language models\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")  # Multilingual model for English\n",
        "nlp_es = spacy.load(\"es_core_news_sm\") # Multilingual model for Spanish\n",
        "nlp_hi = spacy.load(\"xx_ent_wiki_sm\")  # Multilingual model for Hindi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced query parsing for Hindi\n",
        "def parse_hindi_query(query):\n",
        "    return tokenize(query, 'hi')"
      ],
      "metadata": {
        "id": "pQ51z4TQ9Zkd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CoUt8iPYuH8S"
      },
      "outputs": [],
      "source": [
        "from langdetect import detect\n",
        "\n",
        "def detect_language(query):\n",
        "    try:\n",
        "        return langid.classify(query)[0]\n",
        "        # return detect(query)\n",
        "    except Exception as e:\n",
        "        return \"Error: \" + str(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gMtycYb2uN4l"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the language model for each language\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_es = spacy.load(\"es_core_news_sm\")\n",
        "nlp_hi = spacy.load(\"en_core_web_sm\")  # Hindi is not directly supported, so using a multilingual model\n",
        "\n",
        "def parse_query(query, lang):\n",
        "    if lang == 'en':\n",
        "        doc = nlp_en(query)\n",
        "    elif lang == 'es':\n",
        "        doc = nlp_es(query)\n",
        "        print(doc)\n",
        "    elif lang == 'hi':\n",
        "        doc = parse_hindi_query(query)\n",
        "    else:\n",
        "        return \"Unsupported language\"\n",
        "\n",
        "    keywords = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return keywords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rwa27hNGuYRl"
      },
      "outputs": [],
      "source": [
        "def process_query(query):\n",
        "    lang = detect_language(query)\n",
        "    if \"Error\" in lang:\n",
        "        return lang\n",
        "\n",
        "    if lang == 'hi':\n",
        "        # For Hindi, directly use the tokenized output\n",
        "        keywords = parse_hindi_query(query)\n",
        "    else:\n",
        "        # For other languages, continue using spaCy\n",
        "        if lang == 'en':\n",
        "            doc = nlp_en(query)\n",
        "        elif lang == 'es':\n",
        "            doc = nlp_es(query)\n",
        "        else:\n",
        "            return \"Unsupported language\"\n",
        "        keywords = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
        "\n",
        "    return {\"language\": lang, \"keywords\": keywords}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nhDGVuCu2Va",
        "outputId": "79d46e04-d0fe-44d6-afa6-bcc03715b7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How to make traditional Mexican guacamole?\n",
            "Result: {'language': 'en', 'keywords': ['traditional', 'mexican', 'guacamole']}\n",
            "\n",
            "Query: Receta de paella de mariscos\n",
            "Result: {'language': 'es', 'keywords': ['Receta', 'paella', 'marisco']}\n",
            "\n",
            "Query: बर्गर चिकन की रेसिपी\n",
            "Result: {'language': 'hi', 'keywords': ['▁बर्ग', 'र', '▁चिकन', '▁की', '▁रे', 'सिप', 'ी']}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample_queries = [\"How to make traditional Mexican guacamole?\", \"Receta de paella de mariscos\", \"बर्गर चिकन की रेसिपी\"]\n",
        "\n",
        "for query in sample_queries:\n",
        "    result = process_query(query)\n",
        "    print(f\"Query: {query}\\nResult: {result}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npKyMLdMvFwZ",
        "outputId": "b28efd16-bbc2-4073-eedd-15926b8b965b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The detected language for the query is:  en\n",
            "{'hindi': 'पारंपरिक मैक्सिकन गुआकामोल कैसे बनाएं?', 'spanish': '¿Cómo hacer guacamole mexicano tradicional?', 'english': 'How to make traditional Mexican guacamole?'}\n",
            "\n",
            "\n",
            "The detected language for the query is:  es\n",
            "{'hindi': 'सीफूड पेला नुस्खा', 'spanish': 'Receta de paella de mariscos', 'english': 'Seafood Paella Recipe'}\n",
            "\n",
            "\n",
            "The detected language for the query is:  hi\n",
            "{'hindi': 'बटर चिकन की रेसिपी', 'spanish': 'Receta de pollo con mantequilla', 'english': 'Butter chicken recipe'}\n"
          ]
        }
      ],
      "source": [
        "from googletrans import Translator\n",
        "\n",
        "def translate_query(query, target_language):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(query, dest=target_language)\n",
        "    return translation.text\n",
        "\n",
        "def get_translated_queries(user_query):\n",
        "    lang = detect_language(user_query)\n",
        "    print(\"\\n\")\n",
        "    print(\"The detected language for the query is: \", lang)\n",
        "    if lang == \"hi\":\n",
        "        translated_queries = {\n",
        "                'hindi': user_query,\n",
        "                'spanish': translate_query(user_query, 'es'),\n",
        "                'english': translate_query(user_query, 'en')\n",
        "            }\n",
        "    elif lang == \"es\":\n",
        "        translated_queries = {\n",
        "                'hindi': translate_query(user_query, 'hi'),\n",
        "                'spanish': user_query,\n",
        "                'english': translate_query(user_query, 'en')\n",
        "            }\n",
        "    elif lang == \"en\":\n",
        "        translated_queries = {\n",
        "                'hindi': translate_query(user_query, 'hi'),\n",
        "                'spanish': translate_query(user_query, 'es'),\n",
        "                'english': user_query\n",
        "            }\n",
        "    else : # added this else, if there is a scenario of no language detected, translate query into all lang\n",
        "        translated_queries = {\n",
        "                'hindi': translate_query(user_query, 'hi'),\n",
        "                'spanish': translate_query(user_query, 'es'),\n",
        "                'english': translate_query(user_query, 'en')\n",
        "        }\n",
        "\n",
        "    return translated_queries\n",
        "\n",
        "user_queries = [\"How to make traditional Mexican guacamole?\", \"Receta de paella de mariscos\", \"बटर चिकन की रेसिपी\"]\n",
        "for q in user_queries:\n",
        "    print(get_translated_queries(q))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "f44UoVFyTBmd"
      },
      "outputs": [],
      "source": [
        "# Load recipe JSON data\n",
        "with open('recipes.json', 'r') as file:\n",
        "    recipes = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "jiirdlT4UMMs"
      },
      "outputs": [],
      "source": [
        "# Embedding function for text\n",
        "def embed_text(text, model):\n",
        "    return model.encode(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ewZZLxNjEj9D"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "WtTl9DSeUOsk"
      },
      "outputs": [],
      "source": [
        "# Function to embed a recipe\n",
        "def embed_recipe(recipe, model):\n",
        "    combined_text = f\"{recipe['recipeName']} {' '.join(recipe['ingredients'])} {' '.join(recipe['instruction'])}\"\n",
        "    return embed_text(combined_text, model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJSCMISgCMH0"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "qMB6v8E62eHJ"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "yO29v0WQUVYv"
      },
      "outputs": [],
      "source": [
        "# Embedding recipes and building FAISS index\n",
        "database_embeddings = [embed_recipe(recipe, model) for recipe in recipes]\n",
        "dim = len(database_embeddings[0])\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(np.array(database_embeddings).astype('float32'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Ip6biVHlU4Xx"
      },
      "outputs": [],
      "source": [
        "# Function to search the database\n",
        "def search_database(query_embedding, index, database, k=5):\n",
        "    _, indices = index.search(np.array([query_embedding]).astype('float32'), k)\n",
        "    return [database[i] for i in indices[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "osSJhKz8VBJx"
      },
      "outputs": [],
      "source": [
        "# from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# def calculate_ingredient_similarity(recipe_ingredients, query_keywords):\n",
        "#     recipe_ingredients_str = ' '.join(recipe_ingredients)\n",
        "#     query_keywords_str = ' '.join(query_keywords)\n",
        "\n",
        "#     recipe_emb = model.encode(recipe_ingredients_str, convert_to_tensor=True)\n",
        "#     query_emb = model.encode(query_keywords_str, convert_to_tensor=True)\n",
        "\n",
        "#     similarity_score = util.pytorch_cos_sim(recipe_emb, query_emb).item()\n",
        "#     return similarity_score\n",
        "\n",
        "# def calculate_recipe_alignment(recipe, query_keywords):\n",
        "#     recipe_tags_str = ' '.join(recipe)\n",
        "#     query_keywords_str = ' '.join(query_keywords)\n",
        "\n",
        "#     recipe_emb = model.encode(recipe_tags_str, convert_to_tensor=True)\n",
        "#     query_emb = model.encode(query_keywords_str, convert_to_tensor=True)\n",
        "\n",
        "#     alignment_score = util.pytorch_cos_sim(recipe_emb, query_emb).item()\n",
        "#     return alignment_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "qXXg4dqCVcUw"
      },
      "outputs": [],
      "source": [
        "# def calculate_score(recipe, query_keywords, query_language):\n",
        "#     ingredient_similarity = calculate_ingredient_similarity(recipe['ingredients'], query_keywords)\n",
        "#     language_match = 1 if detect_language(recipe['recipeName']) == query_language else 0\n",
        "#     recipe_alignment = calculate_recipe_alignment(recipe['instruction'], query_keywords)\n",
        "#     score = (ingredient_similarity * 0.2) + (language_match * 0.4) + (recipe_alignment * 0.4)\n",
        "#     return score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sentence_transformers import util\n",
        "\n",
        "# def calculate_score(recipe, query_embedding, model):\n",
        "#     # Embed the entire recipe content\n",
        "#     recipe_embedding = embed_recipe(recipe, model)\n",
        "\n",
        "#     # Calculate semantic similarity\n",
        "#     semantic_similarity = util.pytorch_cos_sim(recipe_embedding, query_embedding).item()\n",
        "\n",
        "#     # Old scoring components\n",
        "#     ingredient_similarity = calculate_ingredient_similarity(recipe['ingredients'], query_embedding)\n",
        "#     language_match = 1 if detect_language(recipe['recipeName']) == detect_language(query_embedding) else 0\n",
        "#     recipe_alignment = calculate_recipe_alignment(recipe['instruction'], query_embedding)\n",
        "\n",
        "#     # Combine scores with adjusted weights\n",
        "#     score = (semantic_similarity * 0.5) + (ingredient_similarity * 0.2) + (language_match * 0.2) + (recipe_alignment * 0.1)\n",
        "#     return score\n"
      ],
      "metadata": {
        "id": "_zcRRg0EJ9Q_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util\n",
        "\n",
        "# Calculates ingredient similarity between recipe ingredients and query\n",
        "def calculate_ingredient_similarity(recipe_ingredients, query_embedding, model):\n",
        "    recipe_ingredients_str = ' '.join(recipe_ingredients)\n",
        "\n",
        "    recipe_emb = model.encode(recipe_ingredients_str, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarity between recipe and query embeddings\n",
        "    similarity_score = util.pytorch_cos_sim(recipe_emb, query_embedding).item()\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Calculates alignment of the recipe with user's dietary preferences\n",
        "def calculate_recipe_alignment(recipe_instructions, query_embedding, model):\n",
        "\n",
        "    recipe_instructions_str = ' '.join(recipe_instructions)\n",
        "\n",
        "    recipe_emb = model.encode(recipe_instructions_str, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarity between recipe instructions and query embeddings\n",
        "    alignment_score = util.pytorch_cos_sim(recipe_emb, query_embedding).item()\n",
        "    return alignment_score\n",
        "\n",
        "\n",
        "# Calculates the overall score for a recipe based on various components\n",
        "def calculate_score(recipe, query_embedding, model):\n",
        "    recipe_embedding = embed_recipe(recipe, model)\n",
        "    # Calculate semantic similarity between recipe and query embeddings\n",
        "    semantic_similarity = util.pytorch_cos_sim(recipe_embedding, query_embedding).item()\n",
        "    # Calculate ingredient similarity\n",
        "    ingredient_similarity = calculate_ingredient_similarity(recipe['ingredients'], query_embedding, model)\n",
        "    language_match = 1 if detect_language(recipe['recipeName']) == detect_language(query_embedding) else 0\n",
        "    # Calculate alignment with instructions\n",
        "    recipe_alignment = calculate_recipe_alignment(recipe['instruction'], query_embedding, model)\n",
        "    # Combine all scores with adjusted weights\n",
        "    score = (semantic_similarity * 0.5) + (ingredient_similarity * 0.2) + (language_match * 0.2) + (recipe_alignment * 0.1)\n",
        "    return score\n"
      ],
      "metadata": {
        "id": "sPWh9QrJKu6R"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "Kj49_2pGVjbz"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "# Function to search and score recipes\n",
        "def search_and_score_recipes(query):\n",
        "    translated_queries = get_translated_queries(query)\n",
        "\n",
        "    # Score the search results\n",
        "    scored_results = defaultdict(list)\n",
        "    for lang, translated_query in translated_queries.items():\n",
        "        # Embed the translated queries\n",
        "        query_embedding = embed_text(translated_query, model)\n",
        "        search_results = search_database(query_embedding, index, recipes)\n",
        "        for recipe in search_results:\n",
        "            score = calculate_score(recipe, query_embedding, model)\n",
        "            scored_results[lang].append((recipe, score))\n",
        "\n",
        "    # sort each result in the dictionary\n",
        "    for lang, results in scored_results.items():\n",
        "        scored_results[lang] = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "    return scored_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIATNQ6xVnsu",
        "outputId": "f7d980fb-d032-4510-ba46-ae04bb23aa39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The detected language for the query is:  hi\n",
            "===== Results for HINDI =====\n",
            "1. Recipe: रिसोटो\n",
            "   Score: 0.5913658857345581\n",
            "\n",
            "2. Recipe: टाकोस\n",
            "   Score: 0.5747587442398071\n",
            "\n",
            "3. Recipe: चिकन करी\n",
            "   Score: 0.5744102895259857\n",
            "\n",
            "4. Recipe: गजपाचो\n",
            "   Score: 0.5739732503890992\n",
            "\n",
            "5. Recipe: बिरयानी\n",
            "   Score: 0.562332683801651\n",
            "\n",
            "----------------------------------------\n",
            "===== Results for SPANISH =====\n",
            "1. Recipe: Pollo al Curry\n",
            "   Score: 0.2990070402622223\n",
            "\n",
            "2. Recipe: Burger\n",
            "   Score: 0.28818393051624297\n",
            "\n",
            "3. Recipe: Biryani\n",
            "   Score: 0.28458072543144225\n",
            "\n",
            "4. Recipe: Paneer Tikka\n",
            "   Score: 0.2827745795249939\n",
            "\n",
            "5. Recipe: Paella\n",
            "   Score: 0.28202430009841917\n",
            "\n",
            "----------------------------------------\n",
            "===== Results for ENGLISH =====\n",
            "1. Recipe: Chicken Curry\n",
            "   Score: 0.4906628847122192\n",
            "\n",
            "2. Recipe: Paella\n",
            "   Score: 0.390840619802475\n",
            "\n",
            "3. Recipe: Biryani\n",
            "   Score: 0.3879463255405426\n",
            "\n",
            "4. Recipe: Tacos\n",
            "   Score: 0.3610280632972718\n",
            "\n",
            "5. Recipe: Ramen\n",
            "   Score: 0.3151261150836945\n",
            "\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "user_query = \"चिकन करी\"\n",
        "results = search_and_score_recipes(user_query)\n",
        "\n",
        "for lang, result in results.items():\n",
        "    print(f\"===== Results for {lang.upper()} =====\")\n",
        "    for idx, (recipe, score) in enumerate(result, 1):\n",
        "        print(f\"{idx}. Recipe: {recipe['recipeName']}\\n   Score: {score}\\n\")\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwoxQyo37Nev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0V_JCrl77JSm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}